{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1af7f5",
   "metadata": {},
   "source": [
    "# Prepare BATADAL dataset for Numenta Benchmark (NAB)\n",
    "\n",
    "The [Numenta Benchmark](https://github.com/numenta/NAB) consists of multiple anomaly detection algorithms for time-series. The algorithms identify anomalies contextually - based on previous values for that time series. Therefore the NAB repository expects each time series to be in its own CSV with timestamp and value as the columns.\n",
    "\n",
    "This notebook converts the BATADAL CSV into multiple CSVs, one for each system variable. The three BATADAL datasets are not contiguous, and since NAB is contextual, we only use the test BATADAL dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68515ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe7dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6f8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_anom = pd.read_csv(\"../../data/01_raw/BATADAL_dataset03_train_no_anomaly.csv\")\n",
    "train_some_anom = pd.read_csv(\"../../data/01_raw/BATADAL_dataset04_train_some_anomaly.csv\")\n",
    "test_with_anom = pd.read_csv(\"../../data/01_raw/BATADAL_test_dataset_some_anomaly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df603040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# has leading white space\n",
    "train_some_anom.columns = train_some_anom.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f896f4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8761, 45), (4177, 45), (2089, 44))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_no_anom.shape, train_some_anom.shape, test_with_anom.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf93a5d",
   "metadata": {},
   "source": [
    "# NAB\n",
    "NAB expects a directly containing CSVs with `timestamp, value` as the columns. Therefore we will split each CSV into multiple CSVs as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b815536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = [c for c in test_with_anom.columns if c not in [\"DATETIME\", \"ATT_FLAG\", \"timestamp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a710f",
   "metadata": {},
   "source": [
    "## Split Test Set\n",
    "\n",
    "As NAB finds anomalies at individual time series level by using previous time steps to predict future time steps, we only need the BATADAL test set as it is 3-months of continuous data with anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9084e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_datetime(anomalies: List[Tuple]) -> List[Tuple]:\n",
    "    fmt =\"%d/%m/%Y %H\"\n",
    "    anomalies_dt = [\n",
    "        (pd.to_datetime(s, format=fmt), pd.to_datetime(e, format=fmt)) for s, e in anomalies\n",
    "    ]\n",
    "    \n",
    "    return anomalies_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d808baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_anomaly_column(anomalies: List[Tuple], df: pd.DataFrame) -> pd.DataFrame:        \n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"DATETIME\"], format=\"%d/%m/%y %H\")\n",
    "    df = df.set_index([\"timestamp\"])\n",
    "\n",
    "    df[\"attack\"] = 0\n",
    "    for start, end in anomalies:\n",
    "        df.loc[start:end, \"attack\"] = 1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b04fb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_csv_and_save(\n",
    "    test: pd.DataFrame,\n",
    "    test_anomalies: List[Tuple],\n",
    "    sensor_columns: List[str], \n",
    "    parameters: Dict\n",
    ") -> None:\n",
    "    csv_save_dir = Path(parameters[\"ts_data_dir\"])\n",
    "    label_save_dir = Path(parameters[\"ts_label_dir\"])\n",
    "    csv_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    label_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    anomaly_dict = defaultdict(list)\n",
    "    for c in sensor_columns:\n",
    "        test.reset_index()[[\"timestamp\", c]].rename(\n",
    "            columns={c:\"value\"}\n",
    "        ).to_csv(f\"{csv_save_dir}/{c}.csv\", index=False)\n",
    "\n",
    "        for s_anom, e_anom in test_anomalies:\n",
    "            anomaly_dict[f\"{c}.csv\"].append([\n",
    "                s_anom.strftime('%Y-%m-%d %H:%M:%S.%f'), e_anom.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "            ])\n",
    "            \n",
    "    with open(f\"{label_save_dir}/labels-test.json\", \"w\") as fp:\n",
    "        json.dump(anomaly_dict, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f4523",
   "metadata": {},
   "source": [
    "### Append anomaly column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81d81929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.batadal.net/images/Attacks_TestDataset.png\n",
    "test_anomalies = [\n",
    "    (\"16/01/2017 09\", \"19/01/2017 06\"),\n",
    "    (\"30/01/2017 08\", \"02/02/2017 00\"),\n",
    "    (\"09/02/2017 03\", \"10/02/2017 09\"),\n",
    "    (\"12/02/2017 01\", \"13/02/2017 07\"),\n",
    "    (\"24/02/2017 05\", \"28/02/2017 08\"),\n",
    "    (\"10/03/2017 14\", \"13/03/2017 21\"),\n",
    "    (\"25/03/2017 20\", \"27/03/2017 01\")\n",
    "]\n",
    "\n",
    "test_anomalies_dt = convert_str_datetime(test_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4256ef9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2089, 45)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = append_anomaly_column(test_anomalies_dt, test_with_anom)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bccd0ab",
   "metadata": {},
   "source": [
    "### Save splitted CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72db918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"ts_data_dir\": \"../../data/02_intermediate/iot/ts_data\",\n",
    "    \"ts_label_dir\": \"../../data/02_intermediate/iot/ts_label\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecd0bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_csv_and_save(test_df, test_anomalies_dt, sensor_cols, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32996c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_PU10.csv  F_PU6.csv  L_T3.csv    P_J269.csv  P_J317.csv  S_PU3.csv  S_V2.csv\r\n",
      "F_PU11.csv  F_PU7.csv  L_T4.csv    P_J280.csv  P_J415.csv  S_PU4.csv\r\n",
      "F_PU1.csv   F_PU8.csv  L_T5.csv    P_J289.csv  P_J422.csv  S_PU5.csv\r\n",
      "F_PU2.csv   F_PU9.csv  L_T6.csv    P_J300.csv  S_PU10.csv  S_PU6.csv\r\n",
      "F_PU3.csv   F_V2.csv   L_T7.csv    P_J302.csv  S_PU11.csv  S_PU7.csv\r\n",
      "F_PU4.csv   L_T1.csv   P_J14.csv   P_J306.csv  S_PU1.csv   S_PU8.csv\r\n",
      "F_PU5.csv   L_T2.csv   P_J256.csv  P_J307.csv  S_PU2.csv   S_PU9.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"../../data/02_intermediate/iot/ts_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b126ff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels-combined.json  labels-test.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"../../data/02_intermediate/iot/ts_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05e7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
