{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccdc701",
   "metadata": {},
   "source": [
    "# This notebook is prepared to show eland model training results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "695bf3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "import pickle as pk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss, CosineEmbeddingLoss\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, average_precision_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c81f220",
   "metadata": {},
   "source": [
    "## loading data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d919bf",
   "metadata": {},
   "source": [
    "### user label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1480e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_label = pd.read_csv(\"../../data/02_intermediate/user_behavior/user_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b635b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ultimatt42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jonknee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dons</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jedravent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>burtonmkz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pavel_lishin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sblinn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WebZen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>doodahdei</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tack122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author  label\n",
       "0    ultimatt42      0\n",
       "1       jonknee      0\n",
       "2          dons      0\n",
       "3     Jedravent      0\n",
       "4     burtonmkz      0\n",
       "5  pavel_lishin      0\n",
       "6        sblinn      0\n",
       "7        WebZen      0\n",
       "8     doodahdei      0\n",
       "9       Tack122      0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_label.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74222e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66ff8f60",
   "metadata": {},
   "source": [
    "## user and subreddit topic index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "786696d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/02_intermediate/user_behavior/u2index.pkl\",\"rb\") as f:\n",
    "    u2index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66477419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_o': 0,\n",
       " '138': 1,\n",
       " '13ren': 2,\n",
       " '1812overture': 3,\n",
       " '1esproc': 4,\n",
       " '315was_an_inside_job': 5,\n",
       " '43P04T34': 6,\n",
       " '7oby': 7,\n",
       " 'AAjax': 8,\n",
       " 'ABabyAteMyDingo': 9,\n",
       " 'ANSICL': 10,\n",
       " 'AbouBenAdhem': 11,\n",
       " 'Aerik': 12,\n",
       " 'Ajenthavoc': 13,\n",
       " 'AliasHandler': 14,\n",
       " 'AmericanGoyBlog': 15,\n",
       " 'AngelaMotorman': 16,\n",
       " 'AngledLuffa': 17,\n",
       " 'Anonymous7777': 18,\n",
       " 'AnteChronos': 19,\n",
       " 'ApostrophePosse': 20,\n",
       " 'ArcticCelt': 21,\n",
       " 'Bagel': 22,\n",
       " 'Battleloser': 23,\n",
       " 'BedtimeForSheeple': 24,\n",
       " 'BeetleB': 25,\n",
       " 'Benny_Lava': 26,\n",
       " 'Bensch': 27,\n",
       " 'Bixie': 28,\n",
       " 'Bloodlustt': 29,\n",
       " 'Bloody_Eye': 30,\n",
       " 'BlueBeard': 31,\n",
       " 'BobGaffney': 32,\n",
       " 'BraveSirRobin': 33,\n",
       " 'BrianBoyko': 34,\n",
       " 'Browzer': 35,\n",
       " 'Burlapin': 36,\n",
       " 'Busybyeski': 37,\n",
       " 'CampusTour': 38,\n",
       " 'CannedMango': 39,\n",
       " 'Captain-Obliviouss': 40,\n",
       " 'Chirp08': 41,\n",
       " 'ChunkyLaFunga': 42,\n",
       " 'Ciserus': 43,\n",
       " 'Clothos': 44,\n",
       " 'CodeMonkey1': 45,\n",
       " 'Codebender': 46,\n",
       " 'ColdSnickersBar': 47,\n",
       " 'Cookie': 48,\n",
       " 'CrackIsGoodForYou': 49,\n",
       " 'CrimsonSun99': 50,\n",
       " 'D-Style': 51,\n",
       " 'DCGaymer': 52,\n",
       " 'DOGA': 53,\n",
       " 'DaDibbel': 54,\n",
       " 'Dafuzz': 55,\n",
       " 'Dallas442': 56,\n",
       " 'Dark-Dx': 57,\n",
       " 'DarkSideofOZ': 58,\n",
       " 'Darkmeerkat': 59,\n",
       " 'Dax420': 60,\n",
       " 'Deacon': 61,\n",
       " 'Deestan': 62,\n",
       " 'Dildozer': 63,\n",
       " 'Doeke': 64,\n",
       " 'Doomdoomkittydoom': 65,\n",
       " 'Doomed': 66,\n",
       " 'DoorFrame': 67,\n",
       " 'Dr-No': 68,\n",
       " 'Drevor': 69,\n",
       " 'DudeAsInCool': 70,\n",
       " 'Dzazter': 71,\n",
       " 'EFG': 72,\n",
       " 'Eijin': 73,\n",
       " 'El_Guapo': 74,\n",
       " 'EndymionAwake': 75,\n",
       " 'Entropy': 76,\n",
       " 'Erudecorp': 77,\n",
       " 'Etab': 78,\n",
       " 'EvilPigeon': 79,\n",
       " 'ExplodingBob': 80,\n",
       " 'FANGO': 81,\n",
       " 'FMERCURY': 82,\n",
       " 'Farsay': 83,\n",
       " 'FeedMePlease': 84,\n",
       " 'FenPhen': 85,\n",
       " 'Fidodo': 86,\n",
       " 'Filmore': 87,\n",
       " 'FionaSarah': 88,\n",
       " 'FlySwat': 89,\n",
       " 'Flyen': 90,\n",
       " 'FrancisC': 91,\n",
       " 'Fulltangviper': 92,\n",
       " 'G_Morgan': 93,\n",
       " 'Gargilius': 94,\n",
       " 'GeorgeWBush': 95,\n",
       " 'GetToTheKarateChoppa': 96,\n",
       " 'Grimalkin': 97,\n",
       " 'Grue': 98,\n",
       " 'GrumpySimon': 99,\n",
       " 'GunnerMcGrath': 100,\n",
       " 'Guybrush_Threepwood': 101,\n",
       " 'HardwareLust': 102,\n",
       " 'Haroshia': 103,\n",
       " 'Haven': 104,\n",
       " 'HerbertMcSherbert': 105,\n",
       " 'Hubso': 106,\n",
       " 'HumanSockPuppet': 107,\n",
       " 'HunterTV': 108,\n",
       " 'IConrad': 109,\n",
       " 'I_AM_A_NEOCON': 110,\n",
       " 'Icanhazreddit': 111,\n",
       " 'Indyhouse': 112,\n",
       " 'InkyChan': 113,\n",
       " 'Ioewe': 114,\n",
       " 'James_Johnson': 115,\n",
       " 'JarvisCocker': 116,\n",
       " 'JasonDJ': 117,\n",
       " 'Jedravent': 118,\n",
       " 'JimDabell': 119,\n",
       " 'Jimmy': 120,\n",
       " 'Jivlain': 121,\n",
       " 'Johny_Cash': 122,\n",
       " 'JulianMorrison': 123,\n",
       " 'Kardlonoc': 124,\n",
       " 'KazamaSmokers': 125,\n",
       " 'Kestral': 126,\n",
       " 'Klowner': 127,\n",
       " 'LeviDon': 128,\n",
       " 'Lizard': 129,\n",
       " 'Lukifer': 130,\n",
       " 'Lystrodom': 131,\n",
       " 'MadScientist420': 132,\n",
       " 'MarkByers': 133,\n",
       " 'MarlonBain': 134,\n",
       " 'MarshallBanana': 135,\n",
       " 'MaximumBob': 136,\n",
       " 'McGuirk': 137,\n",
       " 'Midwest_Product': 138,\n",
       " 'MisterEggs': 139,\n",
       " 'MrFlesh': 140,\n",
       " 'MrKlaatu': 141,\n",
       " 'Mr_Smartypants': 142,\n",
       " 'MyaloMark': 143,\n",
       " 'Mythrilfan': 144,\n",
       " 'NSMike': 145,\n",
       " 'NadsatBrat': 146,\n",
       " 'NancyGracesTesticles': 147,\n",
       " 'NastyConde': 148,\n",
       " 'Nate_W': 149,\n",
       " 'Nefelia': 150,\n",
       " 'NoControl': 151,\n",
       " 'NoMoreNicksLeft': 152,\n",
       " 'NoSalt': 153,\n",
       " 'Notmyrealname': 154,\n",
       " 'OMouse': 155,\n",
       " 'Oak': 156,\n",
       " 'OlympicPirate': 157,\n",
       " 'Orangutan': 158,\n",
       " 'OriginalSyn': 159,\n",
       " 'Oryx': 160,\n",
       " 'Osmanthus': 161,\n",
       " 'Othello': 162,\n",
       " 'Papper': 163,\n",
       " 'Petrarch1603': 164,\n",
       " 'Philluminati': 165,\n",
       " 'Pikajabroni': 166,\n",
       " 'Pilebsa': 167,\n",
       " 'PlasmaWhore': 168,\n",
       " 'Poromenos': 169,\n",
       " 'Poultry_In_Motion': 170,\n",
       " 'ProximaC': 171,\n",
       " 'Prysorra': 172,\n",
       " 'Purp': 173,\n",
       " 'Pxorp': 174,\n",
       " 'Qubed': 175,\n",
       " 'Quel': 176,\n",
       " 'QuinnFazigu': 177,\n",
       " 'RKBA': 178,\n",
       " 'RainmadeMan': 179,\n",
       " 'Recoil42': 180,\n",
       " 'RedDyeNumber4': 181,\n",
       " 'ReiToei': 182,\n",
       " 'ReligionOfPeace': 183,\n",
       " 'Resilience': 184,\n",
       " 'RevLoveJoy': 185,\n",
       " 'RexManningDay': 186,\n",
       " 'Richeh': 187,\n",
       " 'RonObvious': 188,\n",
       " 'RonPaulTouchedMe': 189,\n",
       " 'RonaldFuckingPaul': 190,\n",
       " 'RugerRedhawk': 191,\n",
       " 'S7evyn': 192,\n",
       " 'Saiing': 193,\n",
       " 'SamHealer': 194,\n",
       " 'Sangermaine': 195,\n",
       " 'Sarm': 196,\n",
       " 'Satanscock': 197,\n",
       " 'Saydrah': 198,\n",
       " 'Scarker': 199,\n",
       " 'ScornForSega': 200,\n",
       " 'Shaper_pmp': 201,\n",
       " 'SirEdmund': 202,\n",
       " 'SkyMarshal': 203,\n",
       " 'Sle': 204,\n",
       " 'Slipgrid': 205,\n",
       " 'SlvrEagle23': 206,\n",
       " 'Smight': 207,\n",
       " 'SodiumKPump': 208,\n",
       " 'Spacksack': 209,\n",
       " 'Spazsquatch': 210,\n",
       " 'SpikeWolfwood': 211,\n",
       " 'Spudders': 212,\n",
       " 'Squarsh': 213,\n",
       " 'Sqwirl': 214,\n",
       " 'Stingray88': 215,\n",
       " 'StoneMe': 216,\n",
       " 'Stormflux': 217,\n",
       " 'SuperKing': 218,\n",
       " 'Tack122': 219,\n",
       " 'Taladar': 220,\n",
       " 'TheColonel': 221,\n",
       " 'TheKorn': 222,\n",
       " 'TheSOB88': 223,\n",
       " 'The_Ultimate_Reality': 224,\n",
       " 'Thimble': 225,\n",
       " 'ThisIsDave': 226,\n",
       " 'ThrasherC': 227,\n",
       " 'Tommah': 228,\n",
       " 'TripMaster_Monkey': 229,\n",
       " 'Twisted': 230,\n",
       " 'TwoToke': 231,\n",
       " 'UncleOxidant': 232,\n",
       " 'Unfair': 233,\n",
       " 'UntakenUsername': 234,\n",
       " 'Vash265': 235,\n",
       " 'VincentVega12': 236,\n",
       " 'VnlaThndr775': 237,\n",
       " 'VoodooIdol': 238,\n",
       " 'Vreep-eep': 239,\n",
       " 'WebZen': 240,\n",
       " 'Whisper': 241,\n",
       " 'Winoria': 242,\n",
       " 'WipeHandsOnPants': 243,\n",
       " 'Wo1ke': 244,\n",
       " 'XS4Me': 245,\n",
       " 'Xiphorian': 246,\n",
       " 'Yst': 247,\n",
       " 'Zweben': 248,\n",
       " 'a_little_perspective': 249,\n",
       " 'abrahamsen': 250,\n",
       " 'adaminc': 251,\n",
       " 'adleym': 252,\n",
       " 'admiralteal': 253,\n",
       " 'adremeaux': 254,\n",
       " 'adrianmonk': 255,\n",
       " 'aedes': 256,\n",
       " 'ajrw': 257,\n",
       " 'akatherder': 258,\n",
       " 'akatsukix': 259,\n",
       " 'akdas': 260,\n",
       " 'aktufe': 261,\n",
       " 'alaskamiller': 262,\n",
       " 'aletoledo': 263,\n",
       " 'allhands': 264,\n",
       " 'alllie': 265,\n",
       " 'alphabeat': 266,\n",
       " 'amstrdamordeath': 267,\n",
       " 'anachronic': 268,\n",
       " 'andrewd': 269,\n",
       " 'andrewnorris': 270,\n",
       " 'anescient': 271,\n",
       " 'anions': 272,\n",
       " 'anonymous-coward': 273,\n",
       " 'anthropology_nerd': 274,\n",
       " 'antifolkhero': 275,\n",
       " 'apathy': 276,\n",
       " 'api': 277,\n",
       " 'aradil': 278,\n",
       " 'argeaux': 279,\n",
       " 'argoff': 280,\n",
       " 'artman': 281,\n",
       " 'asaturn': 282,\n",
       " 'aschapm': 283,\n",
       " 'assteroid': 284,\n",
       " 'atomicthumbs': 285,\n",
       " 'aussie_bob': 286,\n",
       " 'automatedresponse': 287,\n",
       " 'axord': 288,\n",
       " 'ayrnieu': 289,\n",
       " 'b34nz': 290,\n",
       " 'b3mus3d': 291,\n",
       " 'bad_llama': 292,\n",
       " 'bamobrien': 293,\n",
       " 'bananahead': 294,\n",
       " 'barryicide': 295,\n",
       " 'bart2019': 296,\n",
       " 'baxyjr': 297,\n",
       " 'bazoople': 298,\n",
       " 'bbqribs': 299,\n",
       " 'bcash': 300,\n",
       " 'bebnet': 301,\n",
       " 'benihana': 302,\n",
       " 'blaze4metal': 303,\n",
       " 'bobcat': 304,\n",
       " 'bobpaul': 305,\n",
       " 'boredzo': 306,\n",
       " 'brad-walker': 307,\n",
       " 'brainburger': 308,\n",
       " 'break99': 309,\n",
       " 'breakneckridge': 310,\n",
       " 'brennen': 311,\n",
       " 'broohaha': 312,\n",
       " 'brosephius': 313,\n",
       " 'brufleth': 314,\n",
       " 'btl': 315,\n",
       " 'buffi': 316,\n",
       " 'burtonmkz': 317,\n",
       " 'bushwakko': 318,\n",
       " 'busytigger': 319,\n",
       " 'bw1870': 320,\n",
       " 'cabbit': 321,\n",
       " 'cajolingwilhelm': 322,\n",
       " 'calantorntain': 323,\n",
       " 'captainAwesomePants': 324,\n",
       " 'casicatracha': 325,\n",
       " 'casual_observer': 326,\n",
       " 'cbroberts': 327,\n",
       " 'cefm': 328,\n",
       " 'ch00f': 329,\n",
       " 'chall85': 330,\n",
       " 'christianjb': 331,\n",
       " 'chunky_bacon': 332,\n",
       " 'cocorobot': 333,\n",
       " 'codepoet': 334,\n",
       " 'commonslip': 335,\n",
       " 'contrarian': 336,\n",
       " 'corentin': 337,\n",
       " 'cov': 338,\n",
       " 'cracell': 339,\n",
       " 'crawfishsoul': 340,\n",
       " 'crazybones': 341,\n",
       " 'crusoe': 342,\n",
       " 'cryptoz': 343,\n",
       " 'cuddles666': 344,\n",
       " 'cum_pussy_tits_ass': 345,\n",
       " 'cup': 346,\n",
       " 'cweaver': 347,\n",
       " 'cwzwarich': 348,\n",
       " 'cyber_rigger': 349,\n",
       " 'cyks': 350,\n",
       " 'cypherx': 351,\n",
       " 'd07c0m': 352,\n",
       " 'd42': 353,\n",
       " 'daisy0808': 354,\n",
       " 'danweber': 355,\n",
       " 'darkgatherer': 356,\n",
       " 'davidreiss666': 357,\n",
       " 'db2': 358,\n",
       " 'dead_ed': 359,\n",
       " 'deadsoon': 360,\n",
       " 'defproc': 361,\n",
       " 'dellis': 362,\n",
       " 'derefr': 363,\n",
       " 'desrosiers': 364,\n",
       " 'deuteros': 365,\n",
       " 'dfranke': 366,\n",
       " 'dghughes': 367,\n",
       " 'dhusk': 368,\n",
       " 'diamond': 369,\n",
       " 'dicey': 370,\n",
       " 'digg_suxx_bigg': 371,\n",
       " 'digital': 372,\n",
       " 'diogames': 373,\n",
       " 'diversionmary': 374,\n",
       " 'dlds': 375,\n",
       " 'dmd': 376,\n",
       " 'dmiff': 377,\n",
       " 'dodus': 378,\n",
       " 'dons': 379,\n",
       " 'doodahdei': 380,\n",
       " 'doody': 381,\n",
       " 'dora_explorer': 382,\n",
       " 'dotrob': 383,\n",
       " 'downdiagonal': 384,\n",
       " 'doxiegrl1': 385,\n",
       " 'doyoulikeworms': 386,\n",
       " 'dpzdpz': 387,\n",
       " 'dsk': 388,\n",
       " 'duhblow7': 389,\n",
       " 'duus': 390,\n",
       " 'eOgas': 391,\n",
       " 'earthboundkid': 392,\n",
       " 'eaturbrainz': 393,\n",
       " 'eddie964': 394,\n",
       " 'edguy': 395,\n",
       " 'einexile': 396,\n",
       " 'ejp1082': 397,\n",
       " 'el_pinata': 398,\n",
       " 'elasticsoul': 399,\n",
       " 'elissa1959': 400,\n",
       " 'elquesogrande': 401,\n",
       " 'epicRelic': 402,\n",
       " 'epsilona01': 403,\n",
       " 'eroverton': 404,\n",
       " 'erulabs': 405,\n",
       " 'eusephus': 406,\n",
       " 'executivemonkey': 407,\n",
       " 'f0nd004u': 408,\n",
       " 'fangolo': 409,\n",
       " 'fapman': 410,\n",
       " 'ffualo': 411,\n",
       " 'fingers': 412,\n",
       " 'finix': 413,\n",
       " 'fjhqjv': 414,\n",
       " 'flydog2': 415,\n",
       " 'foonly': 416,\n",
       " 'formido': 417,\n",
       " 'free_man': 418,\n",
       " 'frickindeal': 419,\n",
       " 'frogking': 420,\n",
       " 'frukt': 421,\n",
       " 'frutiger': 422,\n",
       " 'fstorino': 423,\n",
       " 'fuckbuddy': 424,\n",
       " 'fujimitsu': 425,\n",
       " 'fun1ne': 426,\n",
       " 'furry8': 427,\n",
       " 'fwork': 428,\n",
       " 'g0taclue': 429,\n",
       " 'garg': 430,\n",
       " 'garyp714': 431,\n",
       " 'garyr_h': 432,\n",
       " 'geeeeoffff': 433,\n",
       " 'generic_handle': 434,\n",
       " 'geoff422': 435,\n",
       " 'gfixler': 436,\n",
       " 'gid13': 437,\n",
       " 'gigaquack': 438,\n",
       " 'gimeit': 439,\n",
       " 'glmory': 440,\n",
       " 'gmick': 441,\n",
       " 'godlesspinko': 442,\n",
       " 'gonorrhea': 443,\n",
       " 'goodbyeworld': 444,\n",
       " 'grauenwolf': 445,\n",
       " 'gregK': 446,\n",
       " 'greginnj': 447,\n",
       " 'grignr': 448,\n",
       " 'growinglotus': 449,\n",
       " 'guntotingliberal': 450,\n",
       " 'guriboysf': 451,\n",
       " 'gvsteve': 452,\n",
       " 'h0dg3s': 453,\n",
       " 'habbadash': 454,\n",
       " 'happysinger': 455,\n",
       " 'harryballsagna': 456,\n",
       " 'haywire': 457,\n",
       " 'haywire9000': 458,\n",
       " 'hellsbelles': 459,\n",
       " 'hiS_oWn': 460,\n",
       " 'hibryd': 461,\n",
       " 'hiredgoon': 462,\n",
       " 'hitler_rape_abortion': 463,\n",
       " 'hitmonval': 464,\n",
       " 'homeworld': 465,\n",
       " 'hongnanhai': 466,\n",
       " 'honus': 467,\n",
       " 'hotwingbias': 468,\n",
       " 'hpymondays': 469,\n",
       " 'hs4x': 470,\n",
       " 'hypo11': 471,\n",
       " 'illuminatedwax': 472,\n",
       " 'indycysive': 473,\n",
       " 'inferno0000': 474,\n",
       " 'infinite': 475,\n",
       " 'infinityvortex': 476,\n",
       " 'innocentbystander': 477,\n",
       " 'intellectual': 478,\n",
       " 'interstate': 479,\n",
       " 'j2d2': 480,\n",
       " 'jaalin': 481,\n",
       " 'jaggederest': 482,\n",
       " 'jamesallen74': 483,\n",
       " 'jamierc': 484,\n",
       " 'jax9999': 485,\n",
       " 'jayssite': 486,\n",
       " 'je255j': 487,\n",
       " 'jerf': 488,\n",
       " 'jesus4u': 489,\n",
       " 'jfowler27': 490,\n",
       " 'jingo04': 491,\n",
       " 'jjrs': 492,\n",
       " 'jodv': 493,\n",
       " 'joe90210': 494,\n",
       " 'johnfn': 495,\n",
       " 'jon_k': 496,\n",
       " 'jon_titor': 497,\n",
       " 'jones77': 498,\n",
       " 'jonknee': 499,\n",
       " 'jordanlund': 500,\n",
       " 'joshfern': 501,\n",
       " 'jotaroh': 502,\n",
       " 'joyork': 503,\n",
       " 'jozzas': 504,\n",
       " 'judgej2': 505,\n",
       " 'jumpyg1258': 506,\n",
       " 'junkeee999': 507,\n",
       " 'justinhj': 508,\n",
       " 'kalazar': 509,\n",
       " 'kanuk876': 510,\n",
       " 'kareems': 511,\n",
       " 'katsi': 512,\n",
       " 'kdraper': 513,\n",
       " 'kelmr2003': 514,\n",
       " 'kermityfrog': 515,\n",
       " 'ketralnis': 516,\n",
       " 'khafra': 517,\n",
       " 'khoury': 518,\n",
       " 'killerstorm': 519,\n",
       " 'kingkilr': 520,\n",
       " 'kjartanelli': 521,\n",
       " 'knylok': 522,\n",
       " 'kolm': 523,\n",
       " 'kousi': 524,\n",
       " 'kraemahz': 525,\n",
       " 'kraftmatic': 526,\n",
       " 'krizo': 527,\n",
       " 'krugerlive': 528,\n",
       " 'leemy': 529,\n",
       " 'liber8US': 530,\n",
       " 'linkedlist': 531,\n",
       " 'llanor': 532,\n",
       " 'locke2002': 533,\n",
       " 'lockhart000': 534,\n",
       " 'lugfish': 535,\n",
       " 'lylia': 536,\n",
       " 'm1ss1ontomars2k4': 537,\n",
       " 'machrider': 538,\n",
       " 'mackprime': 539,\n",
       " 'madmax_br5': 540,\n",
       " 'malcontent': 541,\n",
       " 'manthrax': 542,\n",
       " 'maqr': 543,\n",
       " 'marthirial': 544,\n",
       " 'martoo': 545,\n",
       " 'masklinn': 546,\n",
       " 'mcantelon': 547,\n",
       " 'mccoyn': 548,\n",
       " 'mchrisneglia': 549,\n",
       " 'me_so_porny': 550,\n",
       " 'megablahblah': 551,\n",
       " 'mexicodoug': 552,\n",
       " 'mindbleach': 553,\n",
       " 'mipadi': 554,\n",
       " 'miparasito': 555,\n",
       " 'mistermoxy': 556,\n",
       " 'miyakohouou': 557,\n",
       " 'mkrfctr': 558,\n",
       " 'mmazing': 559,\n",
       " 'moddestmouse': 560,\n",
       " 'moneyprinter': 561,\n",
       " 'moogle516': 562,\n",
       " 'mooglor': 563,\n",
       " 'moonman': 564,\n",
       " 'moonzilla': 565,\n",
       " 'moriya': 566,\n",
       " 'mothereffingtheresa': 567,\n",
       " 'movzx': 568,\n",
       " 'moxy': 569,\n",
       " 'mrbroom': 570,\n",
       " 'mschaef': 571,\n",
       " 'msdesireeg': 572,\n",
       " 'mturk': 573,\n",
       " 'muhfuhkuh': 574,\n",
       " 'mutatron': 575,\n",
       " 'mynameisdave': 576,\n",
       " 'mynameishere': 577,\n",
       " 'myotheralt': 578,\n",
       " 'mystery_guest': 579,\n",
       " 'natrius': 580,\n",
       " 'neat_stuff': 581,\n",
       " 'neoabraxas': 582,\n",
       " 'neoform3': 583,\n",
       " 'neonic': 584,\n",
       " 'neuquino': 585,\n",
       " 'nevesis': 586,\n",
       " 'nextofpumpkin': 587,\n",
       " 'nfulton': 588,\n",
       " 'ngngboone': 589,\n",
       " 'ngroot': 590,\n",
       " 'nickatnite101': 591,\n",
       " 'nicolaslloyd': 592,\n",
       " 'nihilite': 593,\n",
       " 'nixonrichard': 594,\n",
       " 'njharman': 595,\n",
       " 'nmcyall': 596,\n",
       " 'nooneelse': 597,\n",
       " 'noseeme': 598,\n",
       " 'notor': 599,\n",
       " 'ntr0p3': 600,\n",
       " 'numb3rb0y': 601,\n",
       " 'number6': 602,\n",
       " 'numlok': 603,\n",
       " 'oblivious_human': 604,\n",
       " 'oddmanout': 605,\n",
       " 'officemonkey': 606,\n",
       " 'old_gill': 607,\n",
       " 'ondal': 608,\n",
       " 'onebit': 609,\n",
       " 'oniony': 610,\n",
       " 'orthogonality': 611,\n",
       " 'otakucode': 612,\n",
       " 'otatop': 613,\n",
       " 'otterdam': 614,\n",
       " 'ouroborosity': 615,\n",
       " 'p3do': 616,\n",
       " 'pandemic': 617,\n",
       " 'paro': 618,\n",
       " 'pastanoose': 619,\n",
       " 'pavel_lishin': 620,\n",
       " 'pelirrojo': 621,\n",
       " 'pillage': 622,\n",
       " 'pilto': 623,\n",
       " 'pingish': 624,\n",
       " 'pozorvlak': 625,\n",
       " 'pradador': 626,\n",
       " 'protoopus': 627,\n",
       " 'psdtocode': 628,\n",
       " 'psychometry': 629,\n",
       " 'psyne': 630,\n",
       " 'qarl': 631,\n",
       " 'qgyh2': 632,\n",
       " 'quack': 633,\n",
       " 'quiller': 634,\n",
       " 'r2002': 635,\n",
       " 'raedix': 636,\n",
       " 'rainman_104': 637,\n",
       " 'ralphwiggum': 638,\n",
       " 'randomb0y': 639,\n",
       " 'raouldukeesq': 640,\n",
       " 'rats99ass': 641,\n",
       " 'readdit7': 642,\n",
       " 'rebop': 643,\n",
       " 'reddit_user13': 644,\n",
       " 'redditcensoredme': 645,\n",
       " 'redditrasberry': 646,\n",
       " 'redninja2000': 647,\n",
       " 'rek': 648,\n",
       " 'relic2279': 649,\n",
       " 'reverendfrag4': 650,\n",
       " 'ride': 651,\n",
       " 'rieux': 652,\n",
       " 'ristin': 653,\n",
       " 'rjcarr': 654,\n",
       " 'rmuser': 655,\n",
       " 'robdag2': 656,\n",
       " 'robodale': 657,\n",
       " 'robotevil': 658,\n",
       " 'robotfuel': 659,\n",
       " 'rockicon82': 660,\n",
       " 'rogerssucks': 661,\n",
       " 'roland19d': 662,\n",
       " 'ropers': 663,\n",
       " 'rory096': 664,\n",
       " 'rosshettel': 665,\n",
       " 'rthomas6': 666,\n",
       " 'ryanissuper': 667,\n",
       " 'ryanknapper': 668,\n",
       " 'ryanx27': 669,\n",
       " 'sakebomb69': 670,\n",
       " 'sam512': 671,\n",
       " 'san1ty': 672,\n",
       " 'sarahfrancesca': 673,\n",
       " 'satx': 674,\n",
       " 'sblinn': 675,\n",
       " 'scared1': 676,\n",
       " 'schizobullet': 677,\n",
       " 'sense': 678,\n",
       " 'sfultong': 679,\n",
       " 'shadowsurge': 680,\n",
       " 'shaurz': 681,\n",
       " 'shazbaz': 682,\n",
       " 'sheeprevolution': 683,\n",
       " 'shiner_man': 684,\n",
       " 'shitcovereddick': 685,\n",
       " 'shmi': 686,\n",
       " 'silence_hr': 687,\n",
       " 'sinsyder': 688,\n",
       " 'sketerpot': 689,\n",
       " 'skibybadoowap': 690,\n",
       " 'skippy17': 691,\n",
       " 'skitzh0': 692,\n",
       " 'slenderdog': 693,\n",
       " 'slidinglight': 694,\n",
       " 'slydee': 695,\n",
       " 'smitisme': 696,\n",
       " 'sn0re': 697,\n",
       " 'snair': 698,\n",
       " 'snifty': 699,\n",
       " 'snookums': 700,\n",
       " 'socks': 701,\n",
       " 'somn': 702,\n",
       " 'spaceghoti': 703,\n",
       " 'spez': 704,\n",
       " 'spif': 705,\n",
       " 'spookyvision': 706,\n",
       " 'squidboots': 707,\n",
       " 'squigs': 708,\n",
       " 'srika': 709,\n",
       " 'st_gulik': 710,\n",
       " 'stacecom': 711,\n",
       " 'state_of_alert': 712,\n",
       " 'stesch': 713,\n",
       " 'stomicron': 714,\n",
       " 'stopit': 715,\n",
       " 'stopmotionsunrise': 716,\n",
       " 'stunt_penguin': 717,\n",
       " 'sunshine-x': 718,\n",
       " 'supaphly42': 719,\n",
       " 'swagohome': 720,\n",
       " 'swede': 721,\n",
       " 'sylvan': 722,\n",
       " 'synthpop': 723,\n",
       " 'syroncoda': 724,\n",
       " 'tbotcotw': 725,\n",
       " 'tdehnel': 726,\n",
       " 'thatguydr': 727,\n",
       " 'thax': 728,\n",
       " 'theDrWho': 729,\n",
       " 'the_big_wedding': 730,\n",
       " 'thecompletegeek': 731,\n",
       " 'theeth': 732,\n",
       " 'thekrone': 733,\n",
       " 'thepensivepoet': 734,\n",
       " 'thrakhath': 735,\n",
       " 'throwaway': 736,\n",
       " 'tjdziuba': 737,\n",
       " 'tomjen': 738,\n",
       " 'trackerbishop': 739,\n",
       " 'treebright': 740,\n",
       " 'trenchfever': 741,\n",
       " 'tridentgum': 742,\n",
       " 'trivial': 743,\n",
       " 'troglodyte': 744,\n",
       " 'tryk48s': 745,\n",
       " 'tsteele93': 746,\n",
       " 'tuoder': 747,\n",
       " 'turkourjurbs': 748,\n",
       " 'tvshopceo': 749,\n",
       " 'ubernostrum': 750,\n",
       " 'ubitendo': 751,\n",
       " 'ultimatt42': 752,\n",
       " 'username223': 753,\n",
       " 'ustgblerkvusrd': 754,\n",
       " 'uteunawaytay': 755,\n",
       " 'utexaspunk': 756,\n",
       " 'uwjames': 757,\n",
       " 'vajav': 758,\n",
       " 'valeriepieris': 759,\n",
       " 'vanostran': 760,\n",
       " 'vapblack': 761,\n",
       " 'veracity024': 762,\n",
       " 'veritaze': 763,\n",
       " 'wbeavis': 764,\n",
       " 'wejash': 765,\n",
       " 'whatwedo': 766,\n",
       " 'willis77': 767,\n",
       " 'windmilltheory': 768,\n",
       " 'windynights': 769,\n",
       " 'wolfzero': 770,\n",
       " 'woodsier': 771,\n",
       " 'wurtis16': 772,\n",
       " 'wwabc': 773,\n",
       " 'xMadxScientistx': 774,\n",
       " 'xenmate': 775,\n",
       " 'xinhoj': 776,\n",
       " 'xutopia': 777,\n",
       " 'xyphus': 778,\n",
       " 'yellowking': 779,\n",
       " 'zem': 780,\n",
       " 'zepolen': 781,\n",
       " 'zombieaynrand': 782,\n",
       " 'zombiewat': 783,\n",
       " 'zoomzoom83': 784,\n",
       " 'zorno': 785,\n",
       " 'zyzzogeton': 786}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84d6a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/02_intermediate/user_behavior/p2index.pkl\",\"rb\") as f:\n",
    "    p2index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fbf0b1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AskReddit': 0,\n",
       " 'Drugs': 1,\n",
       " 'Economics': 2,\n",
       " 'Music': 3,\n",
       " 'WTF': 4,\n",
       " 'apple': 5,\n",
       " 'area51': 6,\n",
       " 'atheism': 7,\n",
       " 'bestof': 8,\n",
       " 'business': 9,\n",
       " 'canada': 10,\n",
       " 'cogsci': 11,\n",
       " 'comics': 12,\n",
       " 'entertainment': 13,\n",
       " 'environment': 14,\n",
       " 'funny': 15,\n",
       " 'gadgets': 16,\n",
       " 'gaming': 17,\n",
       " 'geek': 18,\n",
       " 'happy': 19,\n",
       " 'lgbt': 20,\n",
       " 'linux': 21,\n",
       " 'lolcats': 22,\n",
       " 'math': 23,\n",
       " 'netsec': 24,\n",
       " 'nsfw': 25,\n",
       " 'obama': 26,\n",
       " 'offbeat': 27,\n",
       " 'philosophy': 28,\n",
       " 'photography': 29,\n",
       " 'pics': 30,\n",
       " 'politics': 31,\n",
       " 'programming': 32,\n",
       " 'psychology': 33,\n",
       " 'reddit.com': 34,\n",
       " 'science': 35,\n",
       " 'scifi': 36,\n",
       " 'self': 37,\n",
       " 'sex': 38,\n",
       " 'software': 39,\n",
       " 'sports': 40,\n",
       " 'technology': 41,\n",
       " 'videos': 42,\n",
       " 'web_design': 43,\n",
       " 'worldnews': 44,\n",
       " 'xkcd': 45,\n",
       " 'yourweek': 46}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960d877",
   "metadata": {},
   "source": [
    "## edge list data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f3c0822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist_df = pd.read_csv(\"../../data/02_intermediate/user_behavior/edge_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1b4d9d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>retrieved_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ultimatt42</td>\n",
       "      <td>science</td>\n",
       "      <td>1425846806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jonknee</td>\n",
       "      <td>programming</td>\n",
       "      <td>1425846807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>burtonmkz</td>\n",
       "      <td>science</td>\n",
       "      <td>1425846810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pavel_lishin</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1425846810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pavel_lishin</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1425846810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sblinn</td>\n",
       "      <td>politics</td>\n",
       "      <td>1425846810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dons</td>\n",
       "      <td>programming</td>\n",
       "      <td>1425846811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jedravent</td>\n",
       "      <td>politics</td>\n",
       "      <td>1425846811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WebZen</td>\n",
       "      <td>politics</td>\n",
       "      <td>1425846811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>doodahdei</td>\n",
       "      <td>politics</td>\n",
       "      <td>1425846812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author    subreddit  retrieved_on\n",
       "0    ultimatt42      science    1425846806\n",
       "1       jonknee  programming    1425846807\n",
       "2     burtonmkz      science    1425846810\n",
       "3  pavel_lishin   reddit.com    1425846810\n",
       "4  pavel_lishin   reddit.com    1425846810\n",
       "5        sblinn     politics    1425846810\n",
       "6          dons  programming    1425846811\n",
       "7     Jedravent     politics    1425846811\n",
       "8        WebZen     politics    1425846811\n",
       "9     doodahdei     politics    1425846812"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgelist_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1769afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "def process_edgelist(edge_list, u2index, p2index):\n",
    "    \"\"\" Load edge list and construct a graph \"\"\"\n",
    "    edges = Counter()\n",
    "\n",
    "    for i, row in edge_list.iterrows():\n",
    "        #u = row[0]\n",
    "        #p = row[1]\n",
    "        #t = row[2]\n",
    "        u = row['author']\n",
    "        p = row['subreddit']\n",
    "        t = row['retrieved_on']\n",
    "\n",
    "        if i<1:\n",
    "            print(u, p, t)\n",
    "        edges[(u2index[u], p2index[p])] += 1\n",
    "    # Construct the graph\n",
    "    row = []\n",
    "    col = []\n",
    "    entry = []\n",
    "    for edge, w in edges.items():\n",
    "        #print(w)\n",
    "        i, j = edge\n",
    "        row.append(i)\n",
    "        col.append(j)\n",
    "        entry.append(w)\n",
    "    graph = csr_matrix(\n",
    "        (entry, (row, col)), \n",
    "        shape=(len(u2index), len(p2index))\n",
    "    )   \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7f2318dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultimatt42 science 1425846806\n"
     ]
    }
   ],
   "source": [
    "graph = process_edgelist(edgelist_df, u2index, p2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "67e6187a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98302c9c",
   "metadata": {},
   "source": [
    "## train/validation/test id split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ddbc133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/02_intermediate/user_behavior/data_tvt.pkl\",\"rb\") as f:\n",
    "    tvt_idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "48a401bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train, idx_val, idx_test = tvt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "15a61f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((314,), (79,), (393,))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train.shape, idx_val.shape, idx_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacbd1c4",
   "metadata": {},
   "source": [
    "### convert label format (to numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e5f1f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(labels: pd.DataFrame) -> np.array:\n",
    "    \"\"\"process label information\"\"\"\n",
    "    u_all = set()\n",
    "    pos_uids = set()\n",
    "    labeled_uids = set()\n",
    "    #convert a dataframe to an numpy array, array index being mapped indexes from u2index\n",
    "    for i,row in labels.iterrows():\n",
    "        author = row['author']\n",
    "        author_label = row['label']\n",
    "        u_all.add(author)\n",
    "        if author_label == 1:\n",
    "            pos_uids.add(author)\n",
    "            labeled_uids.add(author)\n",
    "        elif author_label == 0:\n",
    "            labeled_uids.add(author)\n",
    "    print(f'loaded labels, total of {len(pos_uids)} positive users and {len(labeled_uids)} labeled users')\n",
    "    labels = np.zeros(len(u2index))\n",
    "    for u in u2index:\n",
    "        if u in pos_uids:\n",
    "            labels[u2index[u]] = 1\n",
    "    labels = labels.astype(int)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08493fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels, total of 327 positive users and 787 labeled users\n"
     ]
    }
   ],
   "source": [
    "labels = process_label(user_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d62ed976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: total of   314 users with   131 pos users and   183 neg users\n",
      "Val:   total of    79 users with    38 pos users and    41 neg users\n",
      "Test:  total of   393 users with   157 pos users and   236 neg users\n"
     ]
    }
   ],
   "source": [
    "print('Train: total of {:5} users with {:5} pos users and {:5} neg users'.format(\n",
    "    len(idx_train), \n",
    "    np.sum(labels[idx_train]), \n",
    "    len(idx_train)-np.sum(labels[idx_train]))\n",
    "     )\n",
    "print('Val:   total of {:5} users with {:5} pos users and {:5} neg users'.format(\n",
    "    len(idx_val), \n",
    "    np.sum(labels[idx_val]), \n",
    "    len(idx_val)-np.sum(labels[idx_val]))\n",
    "     )\n",
    "print('Test:  total of {:5} users with {:5} pos users and {:5} neg users'.format(\n",
    "    len(idx_test), \n",
    "    np.sum(labels[idx_test]), \n",
    "    len(idx_test)-np.sum(labels[idx_test]))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5ef0ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = np.load(\"../../data/02_intermediate/user_behavior/user2vec_npy.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "16110f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(787, 300)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features['data'].shape #787 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0b3fbce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = np.load(\"../../data/02_intermediate/user_behavior/prod2vec_npy.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ac8f7718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 300)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features['data'].shape #47 topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65575b54",
   "metadata": {},
   "source": [
    "## setting up the model trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fb673e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append('/home/ec2-user/SageMaker/anomaly-detection-spatial-temporal-data/')\n",
    "sys.path.append('/home/ec2-user/SageMaker/anomaly-detection-spatial-temporal-data/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4eedd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomaly_detection_spatial_temporal_data.model.data_loader import DynamicGraphWNFDataSet, DynamicGraphWNodeFeatDatasetLoader\n",
    "from anomaly_detection_spatial_temporal_data.model.dynamic_graph import Eland_e2e\n",
    "from anomaly_detection_spatial_temporal_data.model.model_config import ElandConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d466f",
   "metadata": {},
   "source": [
    "### set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8a6f9bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels, total of 327 positive users and 787 labeled users\n",
      "Train: total of   314 users with   131 pos users and   183 neg users\n",
      "Val:   total of    79 users with    38 pos users and    41 neg users\n",
      "Test:  total of   393 users with   157 pos users and   236 neg users\n"
     ]
    }
   ],
   "source": [
    "data_loader = DynamicGraphWNodeFeatDatasetLoader(\n",
    "    user_label, \n",
    "    u2index, \n",
    "    p2index, \n",
    "    edgelist_df, \n",
    "    tvt_idx, \n",
    "    user_features['data'], \n",
    "    item_features['data']\n",
    ")\n",
    "\n",
    "#sequential data loader\n",
    "dataset = DynamicGraphWNFDataSet(p2index, item_features['data'], edgelist_df)\n",
    "lstm_dataloader = DataLoader(dataset, batch_size=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8dbf439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "        'graph': data_loader.graph, \n",
    "        'lstm_dataloader': lstm_dataloader,\n",
    "        'user_features': data_loader.user_features,\n",
    "        'item_features': data_loader.item_features,\n",
    "        'labels': data_loader.labels,\n",
    "        'tvt_nids': data_loader.tvt_idx,\n",
    "        'u2index': data_loader.u2index,\n",
    "        'p2index': data_loader.p2index\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53591b4",
   "metadata": {},
   "source": [
    "### load model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3a16b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8961cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_file = '../../conf/base/parameters/eland.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "afc4861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eland_data_load_options': {'dataset': 'reddit', 'baseline': 'store_true'}, 'eland_model_options': {'dim_feats': 300, 'cuda': 0, 'hidden_size': 128, 'n_layers': 2, 'epochs': 50, 'batch_size': 300, 'seed': -1, 'lr': 0.0001, 'log': True, 'weight_decay': 1e-06, 'dropout': 0.4, 'tensorboard': False, 'name': 'debug', 'gnnlayer_type': 'gcn', 'rnn_type': 'lstm', 'pretrain_bm': 25, 'pretrain_nc': 200, 'alpha': 0.05, 'bmloss_type': 'mse', 'device': 'cpu', 'base_pred': 400, 'save_directory': 'data/07_model_output/user_behavior'}}\n"
     ]
    }
   ],
   "source": [
    "with open(model_config_file, \"r\") as stream:\n",
    "    try:\n",
    "        mode_config=yaml.safe_load(stream)\n",
    "        print(mode_config)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3e90c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open a log directory for notebook training session \n",
    "from pathlib import Path\n",
    "log_dir = Path('logs/')\n",
    "log_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "71d97982",
   "metadata": {},
   "outputs": [],
   "source": [
    "eland_config = ElandConfig(mode_config['eland_model_options'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030c366",
   "metadata": {},
   "source": [
    "#### adjust model directory for notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1790e9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/07_model_output/user_behavior'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eland_config.save_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bd18f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "eland_config.save_directory = '../../data/07_model_output/user_behavior/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "09a68648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/07_model_output/user_behavior/'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eland_config.save_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619487d",
   "metadata": {},
   "source": [
    "## kick off model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6026d4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 19:53:31,316 - Parameters: {'dim_feats': 300, 'hidden_size': 128, 'n_layers': 2, 'lr': 0.0001, 'weight_decay': 1e-06, 'dropout': 0.4, 'gnnlayer_type': 'gcn', 'rnn_type': 'lstm', 'bmloss_type': 'mse'}\n",
      "2022-07-22 19:53:36,365 - BM Module pretrain, Epoch 1/25: loss 105.70482286\n",
      "2022-07-22 19:53:40,729 - BM Module pretrain, Epoch 2/25: loss 99.68473085\n",
      "2022-07-22 19:53:45,593 - BM Module pretrain, Epoch 3/25: loss 91.29374441\n",
      "2022-07-22 19:53:49,726 - BM Module pretrain, Epoch 4/25: loss 79.55009143\n",
      "2022-07-22 19:53:53,783 - BM Module pretrain, Epoch 5/25: loss 65.8869578\n",
      "2022-07-22 19:53:58,441 - BM Module pretrain, Epoch 6/25: loss 53.72576078\n",
      "2022-07-22 19:54:02,598 - BM Module pretrain, Epoch 7/25: loss 45.002189\n",
      "2022-07-22 19:54:08,097 - BM Module pretrain, Epoch 8/25: loss 38.43296417\n",
      "2022-07-22 19:54:12,472 - BM Module pretrain, Epoch 9/25: loss 32.70000505\n",
      "2022-07-22 19:54:16,636 - BM Module pretrain, Epoch 10/25: loss 27.95659669\n",
      "2022-07-22 19:54:21,846 - BM Module pretrain, Epoch 11/25: loss 24.25851281\n",
      "2022-07-22 19:54:26,635 - BM Module pretrain, Epoch 12/25: loss 21.6844457\n",
      "2022-07-22 19:54:31,845 - BM Module pretrain, Epoch 13/25: loss 19.96404966\n",
      "2022-07-22 19:54:37,371 - BM Module pretrain, Epoch 14/25: loss 18.75825842\n",
      "2022-07-22 19:54:41,576 - BM Module pretrain, Epoch 15/25: loss 17.9145054\n",
      "2022-07-22 19:54:45,829 - BM Module pretrain, Epoch 16/25: loss 17.29407589\n",
      "2022-07-22 19:54:51,142 - BM Module pretrain, Epoch 17/25: loss 16.86265238\n",
      "2022-07-22 19:54:55,568 - BM Module pretrain, Epoch 18/25: loss 16.54282928\n",
      "2022-07-22 19:55:00,387 - BM Module pretrain, Epoch 19/25: loss 16.34159565\n",
      "2022-07-22 19:55:05,875 - BM Module pretrain, Epoch 20/25: loss 16.23352393\n",
      "2022-07-22 19:55:10,468 - BM Module pretrain, Epoch 21/25: loss 16.16166814\n",
      "2022-07-22 19:55:14,441 - BM Module pretrain, Epoch 22/25: loss 16.09482821\n",
      "2022-07-22 19:55:20,126 - BM Module pretrain, Epoch 23/25: loss 16.05328806\n",
      "2022-07-22 19:55:24,374 - BM Module pretrain, Epoch 24/25: loss 16.0389053\n",
      "2022-07-22 19:55:28,740 - BM Module pretrain, Epoch 25/25: loss 16.00383035\n",
      "2022-07-22 19:55:28,786 - NCNet pretrain, Epoch [1 / 200]: loss 0.8387, training auc: 0.2286, val_auc 0.0212, test auc 0.0179\n",
      "2022-07-22 19:55:28,827 - NCNet pretrain, Epoch [2 / 200]: loss 0.8131, training auc: 0.3219, val_auc 0.0218, test auc 0.0186\n",
      "2022-07-22 19:55:28,869 - NCNet pretrain, Epoch [3 / 200]: loss 0.8189, training auc: 0.2687, val_auc 0.0250, test auc 0.0209\n",
      "2022-07-22 19:55:28,913 - NCNet pretrain, Epoch [4 / 200]: loss 0.8065, training auc: 0.4176, val_auc 0.0340, test auc 0.0266\n",
      "2022-07-22 19:55:28,957 - NCNet pretrain, Epoch [5 / 200]: loss 0.8005, training auc: 0.4531, val_auc 0.0578, test auc 0.0460\n",
      "2022-07-22 19:55:28,998 - NCNet pretrain, Epoch [6 / 200]: loss 0.7884, training auc: 0.5855, val_auc 0.2003, test auc 0.2462\n",
      "2022-07-22 19:55:29,041 - NCNet pretrain, Epoch [7 / 200]: loss 0.7976, training auc: 0.4154, val_auc 0.5944, test auc 0.6563\n",
      "2022-07-22 19:55:29,083 - NCNet pretrain, Epoch [8 / 200]: loss 0.7812, training auc: 0.5991, val_auc 0.9230, test auc 0.9211\n",
      "2022-07-22 19:55:29,127 - NCNet pretrain, Epoch [9 / 200]: loss 0.7942, training auc: 0.4690, val_auc 0.9949, test auc 0.9826\n",
      "2022-07-22 19:55:29,167 - NCNet pretrain, Epoch [10 / 200]: loss 0.7808, training auc: 0.5953, val_auc 0.9961, test auc 0.9836\n",
      "2022-07-22 19:55:29,204 - NCNet pretrain, Epoch [11 / 200]: loss 0.7867, training auc: 0.5162, val_auc 0.9936\n",
      "2022-07-22 19:55:29,236 - NCNet pretrain, Epoch [12 / 200]: loss 0.7594, training auc: 0.7464, val_auc 0.9917\n",
      "2022-07-22 19:55:29,269 - NCNet pretrain, Epoch [13 / 200]: loss 0.7726, training auc: 0.6591, val_auc 0.9891\n",
      "2022-07-22 19:55:29,305 - NCNet pretrain, Epoch [14 / 200]: loss 0.7640, training auc: 0.6455, val_auc 0.9884\n",
      "2022-07-22 19:55:29,349 - NCNet pretrain, Epoch [15 / 200]: loss 0.7651, training auc: 0.6772, val_auc 0.9872\n",
      "2022-07-22 19:55:29,393 - NCNet pretrain, Epoch [16 / 200]: loss 0.7492, training auc: 0.8139, val_auc 0.9865\n",
      "2022-07-22 19:55:29,432 - NCNet pretrain, Epoch [17 / 200]: loss 0.7438, training auc: 0.8009, val_auc 0.9865\n",
      "2022-07-22 19:55:29,467 - NCNet pretrain, Epoch [18 / 200]: loss 0.7359, training auc: 0.8478, val_auc 0.9865\n",
      "2022-07-22 19:55:29,514 - NCNet pretrain, Epoch [19 / 200]: loss 0.7383, training auc: 0.8223, val_auc 0.9859\n",
      "2022-07-22 19:55:29,549 - NCNet pretrain, Epoch [20 / 200]: loss 0.7362, training auc: 0.8717, val_auc 0.9852\n",
      "2022-07-22 19:55:29,583 - NCNet pretrain, Epoch [21 / 200]: loss 0.7265, training auc: 0.9056, val_auc 0.9852\n",
      "2022-07-22 19:55:29,618 - NCNet pretrain, Epoch [22 / 200]: loss 0.7357, training auc: 0.8326, val_auc 0.9846\n",
      "2022-07-22 19:55:29,652 - NCNet pretrain, Epoch [23 / 200]: loss 0.7290, training auc: 0.8788, val_auc 0.9846\n",
      "2022-07-22 19:55:29,691 - NCNet pretrain, Epoch [24 / 200]: loss 0.7265, training auc: 0.8875, val_auc 0.9846\n",
      "2022-07-22 19:55:29,737 - NCNet pretrain, Epoch [25 / 200]: loss 0.7407, training auc: 0.8179, val_auc 0.9846\n",
      "2022-07-22 19:55:29,775 - NCNet pretrain, Epoch [26 / 200]: loss 0.7218, training auc: 0.8897, val_auc 0.9846\n",
      "2022-07-22 19:55:29,809 - NCNet pretrain, Epoch [27 / 200]: loss 0.7192, training auc: 0.8873, val_auc 0.9846\n",
      "2022-07-22 19:55:29,843 - NCNet pretrain, Epoch [28 / 200]: loss 0.7008, training auc: 0.9421, val_auc 0.9846\n",
      "2022-07-22 19:55:29,876 - NCNet pretrain, Epoch [29 / 200]: loss 0.7123, training auc: 0.9404, val_auc 0.9846\n",
      "2022-07-22 19:55:29,913 - NCNet pretrain, Epoch [30 / 200]: loss 0.7122, training auc: 0.9115, val_auc 0.9846\n",
      "2022-07-22 19:55:29,948 - NCNet pretrain, Epoch [31 / 200]: loss 0.7077, training auc: 0.8896, val_auc 0.9846\n",
      "2022-07-22 19:55:29,983 - NCNet pretrain, Epoch [32 / 200]: loss 0.7026, training auc: 0.9354, val_auc 0.9846\n",
      "2022-07-22 19:55:30,016 - NCNet pretrain, Epoch [33 / 200]: loss 0.6967, training auc: 0.9188, val_auc 0.9852\n",
      "2022-07-22 19:55:30,048 - NCNet pretrain, Epoch [34 / 200]: loss 0.6935, training auc: 0.9314, val_auc 0.9852\n",
      "2022-07-22 19:55:30,088 - NCNet pretrain, Epoch [35 / 200]: loss 0.6870, training auc: 0.9532, val_auc 0.9852\n",
      "2022-07-22 19:55:30,128 - NCNet pretrain, Epoch [36 / 200]: loss 0.6921, training auc: 0.9475, val_auc 0.9852\n",
      "2022-07-22 19:55:30,185 - NCNet pretrain, Epoch [37 / 200]: loss 0.6900, training auc: 0.9340, val_auc 0.9859\n",
      "2022-07-22 19:55:30,226 - NCNet pretrain, Epoch [38 / 200]: loss 0.6772, training auc: 0.9565, val_auc 0.9859\n",
      "2022-07-22 19:55:30,262 - NCNet pretrain, Epoch [39 / 200]: loss 0.6909, training auc: 0.9271, val_auc 0.9865\n",
      "2022-07-22 19:55:30,301 - NCNet pretrain, Epoch [40 / 200]: loss 0.6790, training auc: 0.9363, val_auc 0.9865\n",
      "2022-07-22 19:55:30,339 - NCNet pretrain, Epoch [41 / 200]: loss 0.6734, training auc: 0.9546, val_auc 0.9865\n",
      "2022-07-22 19:55:30,372 - NCNet pretrain, Epoch [42 / 200]: loss 0.6784, training auc: 0.9288, val_auc 0.9865\n",
      "2022-07-22 19:55:30,406 - NCNet pretrain, Epoch [43 / 200]: loss 0.6657, training auc: 0.9624, val_auc 0.9865\n",
      "2022-07-22 19:55:30,442 - NCNet pretrain, Epoch [44 / 200]: loss 0.6734, training auc: 0.9549, val_auc 0.9859\n",
      "2022-07-22 19:55:30,479 - NCNet pretrain, Epoch [45 / 200]: loss 0.6744, training auc: 0.9655, val_auc 0.9859\n",
      "2022-07-22 19:55:30,522 - NCNet pretrain, Epoch [46 / 200]: loss 0.6579, training auc: 0.9644, val_auc 0.9859\n",
      "2022-07-22 19:55:30,568 - NCNet pretrain, Epoch [47 / 200]: loss 0.6637, training auc: 0.9570, val_auc 0.9859\n",
      "2022-07-22 19:55:30,603 - NCNet pretrain, Epoch [48 / 200]: loss 0.6687, training auc: 0.9565, val_auc 0.9859\n",
      "2022-07-22 19:55:30,637 - NCNet pretrain, Epoch [49 / 200]: loss 0.6433, training auc: 0.9668, val_auc 0.9859\n",
      "2022-07-22 19:55:30,669 - NCNet pretrain, Epoch [50 / 200]: loss 0.6342, training auc: 0.9758, val_auc 0.9859\n",
      "2022-07-22 19:55:30,702 - NCNet pretrain, Epoch [51 / 200]: loss 0.6596, training auc: 0.9635, val_auc 0.9852\n",
      "2022-07-22 19:55:30,757 - NCNet pretrain, Epoch [52 / 200]: loss 0.6554, training auc: 0.9679, val_auc 0.9852\n",
      "2022-07-22 19:55:30,797 - NCNet pretrain, Epoch [53 / 200]: loss 0.6318, training auc: 0.9769, val_auc 0.9852\n",
      "2022-07-22 19:55:30,828 - NCNet pretrain, Epoch [54 / 200]: loss 0.6595, training auc: 0.9618, val_auc 0.9852\n",
      "2022-07-22 19:55:30,860 - NCNet pretrain, Epoch [55 / 200]: loss 0.6440, training auc: 0.9731, val_auc 0.9846\n",
      "2022-07-22 19:55:30,901 - NCNet pretrain, Epoch [56 / 200]: loss 0.6473, training auc: 0.9761, val_auc 0.9846\n",
      "2022-07-22 19:55:30,933 - NCNet pretrain, Epoch [57 / 200]: loss 0.6410, training auc: 0.9731, val_auc 0.9846\n",
      "2022-07-22 19:55:30,964 - NCNet pretrain, Epoch [58 / 200]: loss 0.6184, training auc: 0.9761, val_auc 0.9846\n",
      "2022-07-22 19:55:31,000 - NCNet pretrain, Epoch [59 / 200]: loss 0.6436, training auc: 0.9669, val_auc 0.9846\n",
      "2022-07-22 19:55:31,033 - NCNet pretrain, Epoch [60 / 200]: loss 0.6356, training auc: 0.9650, val_auc 0.9846\n",
      "2022-07-22 19:55:31,034 - Early stop!\n",
      "2022-07-22 19:55:31,035 - Best Test Results: auc 0.9836, ap 0.9849, f1 0.5709\n",
      "2022-07-22 19:55:55,280 - Eland Training, Epoch [1/50]: loss 3.0129, train_auc: 0.9672, val_auc 0.9840, test_auc 0.9853\n",
      "2022-07-22 19:56:20,227 - Eland Training, Epoch [2/50]: loss 3.0024, train_auc: 0.9747, val_auc 0.9846, test_auc 0.9857\n",
      "2022-07-22 19:56:46,095 - Eland Training, Epoch [3/50]: loss 2.9934, train_auc: 0.9729, val_auc 0.9846\n",
      "2022-07-22 19:57:17,130 - Eland Training, Epoch [4/50]: loss 2.9975, train_auc: 0.9773, val_auc 0.9840\n",
      "2022-07-22 19:57:40,871 - Eland Training, Epoch [5/50]: loss 2.9924, train_auc: 0.9788, val_auc 0.9878, test_auc 0.9853\n",
      "2022-07-22 19:58:05,452 - Eland Training, Epoch [6/50]: loss 2.9956, train_auc: 0.9817, val_auc 0.9846\n",
      "2022-07-22 19:58:28,702 - Eland Training, Epoch [7/50]: loss 2.9898, train_auc: 0.9796, val_auc 0.9859\n",
      "2022-07-22 19:58:52,533 - Eland Training, Epoch [8/50]: loss 2.9854, train_auc: 0.9742, val_auc 0.9846\n",
      "2022-07-22 19:59:17,613 - Eland Training, Epoch [9/50]: loss 2.9842, train_auc: 0.9760, val_auc 0.9852\n",
      "2022-07-22 19:59:41,502 - Eland Training, Epoch [10/50]: loss 2.9675, train_auc: 0.9765, val_auc 0.9840\n",
      "2022-07-22 20:00:10,741 - Eland Training, Epoch [11/50]: loss 2.9899, train_auc: 0.9754, val_auc 0.9852\n",
      "2022-07-22 20:00:36,346 - Eland Training, Epoch [12/50]: loss 2.9791, train_auc: 0.9763, val_auc 0.9846\n",
      "2022-07-22 20:01:01,143 - Eland Training, Epoch [13/50]: loss 2.9762, train_auc: 0.9782, val_auc 0.9846\n",
      "2022-07-22 20:01:28,231 - Eland Training, Epoch [14/50]: loss 2.9661, train_auc: 0.9799, val_auc 0.9859\n",
      "2022-07-22 20:01:52,069 - Eland Training, Epoch [15/50]: loss 2.9693, train_auc: 0.9767, val_auc 0.9846\n",
      "2022-07-22 20:02:16,917 - Eland Training, Epoch [16/50]: loss 2.9607, train_auc: 0.9800, val_auc 0.9846\n",
      "2022-07-22 20:02:42,604 - Eland Training, Epoch [17/50]: loss 2.9750, train_auc: 0.9792, val_auc 0.9852\n",
      "2022-07-22 20:03:12,717 - Eland Training, Epoch [18/50]: loss 2.9495, train_auc: 0.9804, val_auc 0.9846\n",
      "2022-07-22 20:03:41,807 - Eland Training, Epoch [19/50]: loss 2.9589, train_auc: 0.9760, val_auc 0.9859\n",
      "2022-07-22 20:04:05,662 - Eland Training, Epoch [20/50]: loss 2.9489, train_auc: 0.9785, val_auc 0.9859\n",
      "2022-07-22 20:04:30,341 - Eland Training, Epoch [21/50]: loss 2.9547, train_auc: 0.9771, val_auc 0.9852\n",
      "2022-07-22 20:04:57,254 - Eland Training, Epoch [22/50]: loss 2.9540, train_auc: 0.9750, val_auc 0.9840\n",
      "2022-07-22 20:05:23,065 - Eland Training, Epoch [23/50]: loss 2.9625, train_auc: 0.9763, val_auc 0.9846\n",
      "2022-07-22 20:05:47,197 - Eland Training, Epoch [24/50]: loss 2.9552, train_auc: 0.9761, val_auc 0.9846\n",
      "2022-07-22 20:06:13,894 - Eland Training, Epoch [25/50]: loss 2.9524, train_auc: 0.9775, val_auc 0.9865\n",
      "2022-07-22 20:06:40,332 - Eland Training, Epoch [26/50]: loss 2.9493, train_auc: 0.9751, val_auc 0.9840\n",
      "2022-07-22 20:07:05,731 - Eland Training, Epoch [27/50]: loss 2.9317, train_auc: 0.9761, val_auc 0.9840\n",
      "2022-07-22 20:07:29,868 - Eland Training, Epoch [28/50]: loss 2.9420, train_auc: 0.9782, val_auc 0.9852\n",
      "2022-07-22 20:07:55,113 - Eland Training, Epoch [29/50]: loss 2.9390, train_auc: 0.9804, val_auc 0.9859\n",
      "2022-07-22 20:08:20,631 - Eland Training, Epoch [30/50]: loss 2.9358, train_auc: 0.9801, val_auc 0.9852\n",
      "2022-07-22 20:08:45,985 - Eland Training, Epoch [31/50]: loss 2.9488, train_auc: 0.9736, val_auc 0.9865\n",
      "2022-07-22 20:09:10,753 - Eland Training, Epoch [32/50]: loss 2.9201, train_auc: 0.9768, val_auc 0.9846\n",
      "2022-07-22 20:09:37,937 - Eland Training, Epoch [33/50]: loss 2.9313, train_auc: 0.9742, val_auc 0.9846\n",
      "2022-07-22 20:10:03,659 - Eland Training, Epoch [34/50]: loss 2.9276, train_auc: 0.9756, val_auc 0.9846\n",
      "2022-07-22 20:10:29,115 - Eland Training, Epoch [35/50]: loss 2.9346, train_auc: 0.9755, val_auc 0.9840\n",
      "2022-07-22 20:10:57,865 - Eland Training, Epoch [36/50]: loss 2.9315, train_auc: 0.9787, val_auc 0.9852\n",
      "2022-07-22 20:11:26,329 - Eland Training, Epoch [37/50]: loss 2.9353, train_auc: 0.9767, val_auc 0.9859\n",
      "2022-07-22 20:11:50,669 - Eland Training, Epoch [38/50]: loss 2.9207, train_auc: 0.9803, val_auc 0.9846\n",
      "2022-07-22 20:12:15,287 - Eland Training, Epoch [39/50]: loss 2.9185, train_auc: 0.9784, val_auc 0.9846\n",
      "2022-07-22 20:12:39,839 - Eland Training, Epoch [40/50]: loss 2.9146, train_auc: 0.9767, val_auc 0.9833\n",
      "2022-07-22 20:13:04,825 - Eland Training, Epoch [41/50]: loss 2.9211, train_auc: 0.9801, val_auc 0.9846\n",
      "2022-07-22 20:13:30,367 - Eland Training, Epoch [42/50]: loss 2.9169, train_auc: 0.9787, val_auc 0.9852\n",
      "2022-07-22 20:13:55,965 - Eland Training, Epoch [43/50]: loss 2.9132, train_auc: 0.9796, val_auc 0.9840\n",
      "2022-07-22 20:14:23,070 - Eland Training, Epoch [44/50]: loss 2.9107, train_auc: 0.9776, val_auc 0.9846\n",
      "2022-07-22 20:14:48,658 - Eland Training, Epoch [45/50]: loss 2.9115, train_auc: 0.9762, val_auc 0.9833\n",
      "2022-07-22 20:15:15,429 - Eland Training, Epoch [46/50]: loss 2.9175, train_auc: 0.9726, val_auc 0.9846\n",
      "2022-07-22 20:15:39,526 - Eland Training, Epoch [47/50]: loss 2.9026, train_auc: 0.9756, val_auc 0.9852\n",
      "2022-07-22 20:16:04,697 - Eland Training, Epoch [48/50]: loss 2.8994, train_auc: 0.9788, val_auc 0.9859\n",
      "2022-07-22 20:16:30,263 - Eland Training, Epoch [49/50]: loss 2.8998, train_auc: 0.9782, val_auc 0.9833\n",
      "2022-07-22 20:16:54,919 - Eland Training, Epoch [50/50]: loss 2.9158, train_auc: 0.9786, val_auc 0.9840\n",
      "2022-07-22 20:16:54,920 - Best Test Results: auc 0.9857, ap 0.9863, f1 0.9739\n"
     ]
    }
   ],
   "source": [
    "model_obj = Eland_e2e(\n",
    "    data_dict['graph'], \n",
    "    data_dict['lstm_dataloader'], \n",
    "    data_dict['user_features'],\n",
    "    data_dict['item_features'], \n",
    "    data_dict['labels'], \n",
    "    data_dict['tvt_nids'], \n",
    "    data_dict['u2index'],\n",
    "    data_dict['p2index'], \n",
    "    data_dict['item_features'], \n",
    "    eland_config\n",
    ")\n",
    "training_result,save_model_path = model_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "82631f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'train_auc': 0.9672131147540983, 'val_auc': 0.98395378690629},\n",
       " 2: {'train_auc': 0.9746798481625162, 'val_auc': 0.9845956354300385},\n",
       " 3: {'train_auc': 0.9728861636007176, 'val_auc': 0.9845956354300385},\n",
       " 4: {'train_auc': 0.9773078046135234, 'val_auc': 0.98395378690629},\n",
       " 5: {'train_auc': 0.9788094940140991, 'val_auc': 0.9878048780487805},\n",
       " 6: {'train_auc': 0.9816877320318691, 'val_auc': 0.9845956354300385},\n",
       " 7: {'train_auc': 0.9796437659033079, 'val_auc': 0.9858793324775352},\n",
       " 8: {'train_auc': 0.9742209986234514, 'val_auc': 0.9845956354300385},\n",
       " 9: {'train_auc': 0.97601468318525, 'val_auc': 0.9852374839537869},\n",
       " 10: {'train_auc': 0.9764735327243148, 'val_auc': 0.98395378690629},\n",
       " 11: {'train_auc': 0.9754306928628039, 'val_auc': 0.9852374839537869},\n",
       " 12: {'train_auc': 0.9762649647520126, 'val_auc': 0.9845956354300385},\n",
       " 13: {'train_auc': 0.9782255036916531, 'val_auc': 0.9845956354300385},\n",
       " 14: {'train_auc': 0.97985233387561, 'val_auc': 0.9858793324775352},\n",
       " 15: {'train_auc': 0.9766821006966171, 'val_auc': 0.9845956354300385},\n",
       " 16: {'train_auc': 0.9799774746589912, 'val_auc': 0.9845956354300385},\n",
       " 17: {'train_auc': 0.9792266299587036, 'val_auc': 0.9852374839537869},\n",
       " 18: {'train_auc': 0.9803528970091352, 'val_auc': 0.9845956354300385},\n",
       " 19: {'train_auc': 0.97601468318525, 'val_auc': 0.9858793324775352},\n",
       " 20: {'train_auc': 0.9784757852584156, 'val_auc': 0.9858793324775352},\n",
       " 21: {'train_auc': 0.9771409502356818, 'val_auc': 0.9852374839537869},\n",
       " 22: {'train_auc': 0.9749718433237392, 'val_auc': 0.98395378690629},\n",
       " 23: {'train_auc': 0.9763066783464731, 'val_auc': 0.9845956354300385},\n",
       " 24: {'train_auc': 0.9760563967797105, 'val_auc': 0.9845956354300385},\n",
       " 25: {'train_auc': 0.9774746589913652, 'val_auc': 0.9865211810012837},\n",
       " 26: {'train_auc': 0.975138697701581, 'val_auc': 0.98395378690629},\n",
       " 27: {'train_auc': 0.9761398239686314, 'val_auc': 0.98395378690629},\n",
       " 28: {'train_auc': 0.9782255036916531, 'val_auc': 0.9852374839537869},\n",
       " 29: {'train_auc': 0.9803946106035957, 'val_auc': 0.9858793324775352},\n",
       " 30: {'train_auc': 0.9800609018479122, 'val_auc': 0.9852374839537869},\n",
       " 31: {'train_auc': 0.9735535811120843, 'val_auc': 0.9865211810012837},\n",
       " 32: {'train_auc': 0.9768072414799982, 'val_auc': 0.9845956354300385},\n",
       " 33: {'train_auc': 0.9742209986234514, 'val_auc': 0.9845956354300385},\n",
       " 34: {'train_auc': 0.9755975472406457, 'val_auc': 0.9845956354300385},\n",
       " 35: {'train_auc': 0.9754724064572644, 'val_auc': 0.98395378690629},\n",
       " 36: {'train_auc': 0.978684353230718, 'val_auc': 0.9852374839537869},\n",
       " 37: {'train_auc': 0.9767238142910775, 'val_auc': 0.9858793324775352},\n",
       " 38: {'train_auc': 0.9802694698202143, 'val_auc': 0.9845956354300385},\n",
       " 39: {'train_auc': 0.9783923580694949, 'val_auc': 0.9845956354300385},\n",
       " 40: {'train_auc': 0.9767238142910775, 'val_auc': 0.9833119383825416},\n",
       " 41: {'train_auc': 0.9801026154423725, 'val_auc': 0.9845956354300385},\n",
       " 42: {'train_auc': 0.9787260668251783, 'val_auc': 0.9852374839537869},\n",
       " 43: {'train_auc': 0.979560338714387, 'val_auc': 0.98395378690629},\n",
       " 44: {'train_auc': 0.9775580861802861, 'val_auc': 0.9845956354300385},\n",
       " 45: {'train_auc': 0.9762232511575523, 'val_auc': 0.9833119383825417},\n",
       " 46: {'train_auc': 0.972552454845034, 'val_auc': 0.9845956354300385},\n",
       " 47: {'train_auc': 0.9755975472406456, 'val_auc': 0.9852374839537869},\n",
       " 48: {'train_auc': 0.9788094940140991, 'val_auc': 0.9858793324775352},\n",
       " 49: {'train_auc': 0.978225503691653, 'val_auc': 0.9833119383825417},\n",
       " 50: {'train_auc': 0.9785592124473366, 'val_auc': 0.9839537869062901}}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8821e",
   "metadata": {},
   "source": [
    "## read in kedro pipeline training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e2a28c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/07_model_output/user_behavior/train_result.pkl\",\"rb\") as f:\n",
    "    train_result_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ebecd78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'train_auc': 0.9734284403287031, 'val_auc': 0.98395378690629},\n",
       " 2: {'train_auc': 0.9772243774246026, 'val_auc': 0.9826700898587932},\n",
       " 3: {'train_auc': 0.9738455762733075, 'val_auc': 0.9826700898587932},\n",
       " 4: {'train_auc': 0.9714261877946022, 'val_auc': 0.98395378690629},\n",
       " 5: {'train_auc': 0.9789346347974806, 'val_auc': 0.9813863928112965},\n",
       " 6: {'train_auc': 0.9754724064572644, 'val_auc': 0.98395378690629},\n",
       " 7: {'train_auc': 0.9765152463187752, 'val_auc': 0.98395378690629},\n",
       " 8: {'train_auc': 0.9707587702832354, 'val_auc': 0.98395378690629},\n",
       " 9: {'train_auc': 0.9767238142910775, 'val_auc': 0.9826700898587933},\n",
       " 10: {'train_auc': 0.976682100696617, 'val_auc': 0.9826700898587932},\n",
       " 11: {'train_auc': 0.9733032995453218, 'val_auc': 0.9813863928112965},\n",
       " 12: {'train_auc': 0.977057523046761, 'val_auc': 0.98395378690629},\n",
       " 13: {'train_auc': 0.9786843532307179, 'val_auc': 0.9833119383825417},\n",
       " 14: {'train_auc': 0.9766403871021566, 'val_auc': 0.982028241335045},\n",
       " 15: {'train_auc': 0.9737204354899262, 'val_auc': 0.9833119383825417},\n",
       " 16: {'train_auc': 0.9765986735076961, 'val_auc': 0.9845956354300385},\n",
       " 17: {'train_auc': 0.9771826638301423, 'val_auc': 0.9826700898587932},\n",
       " 18: {'train_auc': 0.9734701539231636, 'val_auc': 0.9813863928112965},\n",
       " 19: {'train_auc': 0.9745547073791349, 'val_auc': 0.982028241335045},\n",
       " 20: {'train_auc': 0.9791014891753222, 'val_auc': 0.9833119383825417},\n",
       " 21: {'train_auc': 0.9774746589913652, 'val_auc': 0.98395378690629},\n",
       " 22: {'train_auc': 0.9765569599132357, 'val_auc': 0.9813863928112965},\n",
       " 23: {'train_auc': 0.9746381345680556, 'val_auc': 0.9820282413350448},\n",
       " 24: {'train_auc': 0.9762232511575523, 'val_auc': 0.9820282413350448},\n",
       " 25: {'train_auc': 0.9808117465482, 'val_auc': 0.9813863928112965},\n",
       " 26: {'train_auc': 0.9798523338756102, 'val_auc': 0.982028241335045},\n",
       " 27: {'train_auc': 0.9773912318024442, 'val_auc': 0.9820282413350448},\n",
       " 28: {'train_auc': 0.9783506444750344, 'val_auc': 0.9801026957637998},\n",
       " 29: {'train_auc': 0.9785174988528761, 'val_auc': 0.982028241335045},\n",
       " 30: {'train_auc': 0.9805614649814375, 'val_auc': 0.9813863928112965},\n",
       " 31: {'train_auc': 0.9793517707420848, 'val_auc': 0.9813863928112965},\n",
       " 32: {'train_auc': 0.9790180619864013, 'val_auc': 0.9807445442875482},\n",
       " 33: {'train_auc': 0.9771826638301422, 'val_auc': 0.9826700898587932},\n",
       " 34: {'train_auc': 0.9739290034622283, 'val_auc': 0.9826700898587932},\n",
       " 35: {'train_auc': 0.9780586493138114, 'val_auc': 0.9807445442875481},\n",
       " 36: {'train_auc': 0.9813123096817252, 'val_auc': 0.9813863928112966},\n",
       " 37: {'train_auc': 0.9771826638301423, 'val_auc': 0.9813863928112965},\n",
       " 38: {'train_auc': 0.9788512076085596, 'val_auc': 0.9820282413350448},\n",
       " 39: {'train_auc': 0.9801860426312935, 'val_auc': 0.9826700898587932},\n",
       " 40: {'train_auc': 0.9772243774246027, 'val_auc': 0.9820282413350448},\n",
       " 41: {'train_auc': 0.9780169357193509, 'val_auc': 0.9807445442875481},\n",
       " 42: {'train_auc': 0.9781420765027323, 'val_auc': 0.982028241335045},\n",
       " 43: {'train_auc': 0.981103741709423, 'val_auc': 0.9801026957637997},\n",
       " 44: {'train_auc': 0.9719684645225879, 'val_auc': 0.978818998716303},\n",
       " 45: {'train_auc': 0.9790180619864012, 'val_auc': 0.9833119383825417},\n",
       " 46: {'train_auc': 0.9761398239686313, 'val_auc': 0.9801026957637997},\n",
       " 47: {'train_auc': 0.9753055520794227, 'val_auc': 0.9807445442875481},\n",
       " 48: {'train_auc': 0.9775997997747464, 'val_auc': 0.9833119383825417},\n",
       " 49: {'train_auc': 0.977432945396905, 'val_auc': 0.9813863928112965},\n",
       " 50: {'train_auc': 0.9797271930922288, 'val_auc': 0.9826700898587932}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb7e63",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan Squire, and Jeremy Blackburn. 2020. The Pushshift Reddit Dataset.\n",
    "\n",
    "Tong Zhao, Bo Ni, Wenhao Yu, Zhichun Guo, Neil Shah, and Meng Jiang, 2021. Action Sequence Augmentation for Early Graph-based Anomaly Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea25f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro-eland-venv",
   "language": "python",
   "name": "kedro-eland-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
